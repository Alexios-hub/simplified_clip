












































































































































  2%|█▍                                                                           | 500/27741 [04:43<4:23:32,  1.72it/s][INFO|trainer.py:3057] 2024-03-15 11:50:56,388 >> Saving model checkpoint to ./clip-bert-finetuned/checkpoint-500
[INFO|configuration_utils.py:471] 2024-03-15 11:50:56,390 >> Configuration saved in ./clip-bert-finetuned/checkpoint-500/config.json
[INFO|modeling_utils.py:2470] 2024-03-15 11:50:56,860 >> Model weights saved in ./clip-bert-finetuned/checkpoint-500/model.safetensors
{'loss': 1.4923, 'grad_norm': 24.934646606445312, 'learning_rate': 4.909880682022999e-05, 'epoch': 0.05}















































































































































  4%|██▋                                                                         | 1000/27741 [09:33<4:17:11,  1.73it/s][INFO|trainer.py:3057] 2024-03-15 11:55:46,434 >> Saving model checkpoint to ./clip-bert-finetuned/checkpoint-1000
[INFO|configuration_utils.py:471] 2024-03-15 11:55:46,435 >> Configuration saved in ./clip-bert-finetuned/checkpoint-1000/config.json
[INFO|modeling_utils.py:2470] 2024-03-15 11:55:46,927 >> Model weights saved in ./clip-bert-finetuned/checkpoint-1000/model.safetensors
{'loss': 0.9545, 'grad_norm': 24.871984481811523, 'learning_rate': 4.819761364045997e-05, 'epoch': 0.11}














































































































































  5%|████                                                                        | 1500/27741 [14:23<4:09:59,  1.75it/s][INFO|trainer.py:3057] 2024-03-15 12:00:35,967 >> Saving model checkpoint to ./clip-bert-finetuned/checkpoint-1500
[INFO|configuration_utils.py:471] 2024-03-15 12:00:35,968 >> Configuration saved in ./clip-bert-finetuned/checkpoint-1500/config.json
{'loss': 0.8568, 'grad_norm': 23.68141746520996, 'learning_rate': 4.7296420460689956e-05, 'epoch': 0.16}
[INFO|modeling_utils.py:2470] 2024-03-15 12:00:36,542 >> Model weights saved in ./clip-bert-finetuned/checkpoint-1500/model.safetensors

















































  6%|████▌                                                                       | 1677/27741 [16:06<4:12:19,  1.72it/s]Traceback (most recent call last):
  File "/home/alex/simplified_clip/run_clip.py", line 582, in <module>
    main()
  File "/home/alex/simplified_clip/run_clip.py", line 547, in main
    train_result = trainer.train(resume_from_checkpoint=checkpoint)
  File "/home/alex/simplified_clip/transformers/src/transformers/trainer.py", line 1638, in train
    return inner_training_loop(
  File "/home/alex/simplified_clip/transformers/src/transformers/trainer.py", line 1976, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/alex/simplified_clip/transformers/src/transformers/trainer.py", line 2899, in training_step
    self.accelerator.backward(loss)
  File "/home/alex/miniconda3/envs/sim_clip/lib/python3.10/site-packages/accelerate/accelerator.py", line 2001, in backward
    loss.backward(**kwargs)
  File "/home/alex/miniconda3/envs/sim_clip/lib/python3.10/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/home/alex/miniconda3/envs/sim_clip/lib/python3.10/site-packages/torch/autograd/__init__.py", line 266, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt