Using the latest cached version of the module from /home/alex/.cache/huggingface/modules/datasets_modules/datasets/ydshieh--coco_dataset_script/e033205c0266a54c10be132f9264f2a39dcf893e798f6756d224b1ff5078998f (last modified on Thu Mar 14 12:38:10 2024) since it couldn't be found locally at ydshieh/coco_dataset_script., or remotely on the Hugging Face Hub.
Repo card metadata block was not found. Setting CardData to empty.
simplified transformer
CLIP(
  (visual): VisionTransformer(
    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)
    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ShapedAttentionBlock(
          (attn): ShapedAttention(
            (w_q): Linear(in_features=768, out_features=768, bias=True)
            (w_k): Linear(in_features=768, out_features=768, bias=True)
          )
          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
        )
        (1): ShapedAttentionBlock(
          (attn): ShapedAttention(
            (w_q): Linear(in_features=768, out_features=768, bias=True)
            (w_k): Linear(in_features=768, out_features=768, bias=True)
          )
          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
        )
        (2): ShapedAttentionBlock(
          (attn): ShapedAttention(
            (w_q): Linear(in_features=768, out_features=768, bias=True)
            (w_k): Linear(in_features=768, out_features=768, bias=True)
          )
          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
        )
        (3): ShapedAttentionBlock(
          (attn): ShapedAttention(
            (w_q): Linear(in_features=768, out_features=768, bias=True)
            (w_k): Linear(in_features=768, out_features=768, bias=True)
          )
          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
        )
        (4): ShapedAttentionBlock(
          (attn): ShapedAttention(
            (w_q): Linear(in_features=768, out_features=768, bias=True)
            (w_k): Linear(in_features=768, out_features=768, bias=True)
          )
          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
        )
        (5): ShapedAttentionBlock(
          (attn): ShapedAttention(
            (w_q): Linear(in_features=768, out_features=768, bias=True)
            (w_k): Linear(in_features=768, out_features=768, bias=True)
          )
          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
        )
        (6): ShapedAttentionBlock(
          (attn): ShapedAttention(
            (w_q): Linear(in_features=768, out_features=768, bias=True)
            (w_k): Linear(in_features=768, out_features=768, bias=True)
          )
          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
        )
        (7): ShapedAttentionBlock(
          (attn): ShapedAttention(
            (w_q): Linear(in_features=768, out_features=768, bias=True)
            (w_k): Linear(in_features=768, out_features=768, bias=True)
          )
          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
        )
        (8): ShapedAttentionBlock(
          (attn): ShapedAttention(
            (w_q): Linear(in_features=768, out_features=768, bias=True)
            (w_k): Linear(in_features=768, out_features=768, bias=True)
          )
          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
        )
        (9): ShapedAttentionBlock(
          (attn): ShapedAttention(
            (w_q): Linear(in_features=768, out_features=768, bias=True)
            (w_k): Linear(in_features=768, out_features=768, bias=True)
          )
          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
        )
        (10): ShapedAttentionBlock(
          (attn): ShapedAttention(
            (w_q): Linear(in_features=768, out_features=768, bias=True)
            (w_k): Linear(in_features=768, out_features=768, bias=True)
          )
          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
        )
        (11): ShapedAttentionBlock(
          (attn): ShapedAttention(
            (w_q): Linear(in_features=768, out_features=768, bias=True)
            (w_k): Linear(in_features=768, out_features=768, bias=True)
          )
          (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
        )
      )
    )
    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (transformer): Transformer(
    (resblocks): Sequential(
      (0): ShapedAttentionBlock(
        (attn): ShapedAttention(
          (w_q): Linear(in_features=512, out_features=512, bias=True)
          (w_k): Linear(in_features=512, out_features=512, bias=True)
        )
        (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
      )
      (1): ShapedAttentionBlock(
        (attn): ShapedAttention(
          (w_q): Linear(in_features=512, out_features=512, bias=True)
          (w_k): Linear(in_features=512, out_features=512, bias=True)
        )
        (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
      )
      (2): ShapedAttentionBlock(
        (attn): ShapedAttention(
          (w_q): Linear(in_features=512, out_features=512, bias=True)
          (w_k): Linear(in_features=512, out_features=512, bias=True)
        )
        (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
      )
      (3): ShapedAttentionBlock(
        (attn): ShapedAttention(
          (w_q): Linear(in_features=512, out_features=512, bias=True)
          (w_k): Linear(in_features=512, out_features=512, bias=True)
        )
        (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
      )
      (4): ShapedAttentionBlock(
        (attn): ShapedAttention(
          (w_q): Linear(in_features=512, out_features=512, bias=True)
          (w_k): Linear(in_features=512, out_features=512, bias=True)
        )
        (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
      )
      (5): ShapedAttentionBlock(
        (attn): ShapedAttention(
          (w_q): Linear(in_features=512, out_features=512, bias=True)
          (w_k): Linear(in_features=512, out_features=512, bias=True)
        )
        (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
      )
      (6): ShapedAttentionBlock(
        (attn): ShapedAttention(
          (w_q): Linear(in_features=512, out_features=512, bias=True)
          (w_k): Linear(in_features=512, out_features=512, bias=True)
        )
        (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
      )
      (7): ShapedAttentionBlock(
        (attn): ShapedAttention(
          (w_q): Linear(in_features=512, out_features=512, bias=True)
          (w_k): Linear(in_features=512, out_features=512, bias=True)
        )
        (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
      )
      (8): ShapedAttentionBlock(
        (attn): ShapedAttention(
          (w_q): Linear(in_features=512, out_features=512, bias=True)
          (w_k): Linear(in_features=512, out_features=512, bias=True)
        )
        (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
      )
      (9): ShapedAttentionBlock(
        (attn): ShapedAttention(
          (w_q): Linear(in_features=512, out_features=512, bias=True)
          (w_k): Linear(in_features=512, out_features=512, bias=True)
        )
        (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
      )
      (10): ShapedAttentionBlock(
        (attn): ShapedAttention(
          (w_q): Linear(in_features=512, out_features=512, bias=True)
          (w_k): Linear(in_features=512, out_features=512, bias=True)
        )
        (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
      )
      (11): ShapedAttentionBlock(
        (attn): ShapedAttention(
          (w_q): Linear(in_features=512, out_features=512, bias=True)
          (w_k): Linear(in_features=512, out_features=512, bias=True)
        )
        (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
      )
    )
  )
  (token_embedding): Embedding(49408, 512)
  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
)
Total parameters: 130768641.0




































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 1/10 Loss: 5.7891: 100%|██████████████████████████████████████████████████████| 1156/1156 [53:43<00:00,  2.79s/it]
Epoch 2/10:   0%|                                                                              | 0/1156 [00:00<?, ?it/s]




































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 2/10 Loss: 5.7422: 100%|██████████████████████████████████████████████████████| 1156/1156 [52:57<00:00,  2.75s/it]
Epoch 3/10:   0%|                                                                              | 0/1156 [00:00<?, ?it/s]



































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 3/10 Loss: 5.7344: 100%|██████████████████████████████████████████████████████| 1156/1156 [52:49<00:00,  2.74s/it]
Epoch 4/10:   0%|                                                                              | 0/1156 [00:00<?, ?it/s]



































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 4/10 Loss: 5.7266: 100%|██████████████████████████████████████████████████████| 1156/1156 [52:55<00:00,  2.75s/it]
Epoch 5/10:   0%|                                                                              | 0/1156 [00:00<?, ?it/s]



































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 5/10 Loss: 5.9453: 100%|█████████████████████████████████████████████████████▉| 1155/1156 [52:50<00:02,  2.80s/it]
Epoch 5/10 Loss: 5.7188: 100%|██████████████████████████████████████████████████████| 1156/1156 [52:52<00:00,  2.74s/it]



































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 6/10 Loss: 5.7227: 100%|██████████████████████████████████████████████████████| 1156/1156 [53:00<00:00,  2.75s/it]
Epoch 7/10:   0%|                                                                              | 0/1156 [00:00<?, ?it/s]



































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 7/10 Loss: 5.7188: 100%|██████████████████████████████████████████████████████| 1156/1156 [52:46<00:00,  2.74s/it]
Epoch 8/10:   0%|                                                                              | 0/1156 [00:00<?, ?it/s]
































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 8/10 Loss: 5.7188: 100%|██████████████████████████████████████████████████████| 1156/1156 [52:52<00:00,  2.74s/it]
Epoch Completed: 8/10, Average Loss: 5.8840



































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 9/10 Loss: 5.7031: 100%|██████████████████████████████████████████████████████| 1156/1156 [53:05<00:00,  2.76s/it]
Epoch 10/10:   0%|                                                                             | 0/1156 [00:00<?, ?it/s]




































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Epoch 10/10 Loss: 5.7031: 100%|█████████████████████████████████████████████████████| 1156/1156 [54:06<00:00,  2.81s/it]
Epoch Completed: 10/10, Average Loss: 5.8651